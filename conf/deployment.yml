# Custom section is used to store configurations that might be repetative.
# Please read YAML documentation for details on how to use substitutions and anchors.
custom:
  basic-static-cluster: &basic-static-cluster
    new_cluster:
      # <<: *basic-cluster-props
      num_workers: 0
      node_type_id: "Standard_E16as_v4"
      spark_version: "10.4.x-scala2.12"

# please note that we're using FUSE reference for config file, hence we're going to load this file using its local FS path
environments:
  default:
    workflows:
      - name: "pandarallel-sample"
        <<: *basic-static-cluster
        spark_python_task:
          python_file: "file://freeholdforecast/tasks/pandarallel_sample.py"
      - name: "freeholdforecast-etl-ml"
        <<: *basic-static-cluster
        spark_python_task:
          python_file: "file://freeholdforecast/tasks/etl_ml_task.py"
      #######################################################################################
      # this is an example job with single ETL task based on 2.1 API and wheel_task format #
      ######################################################################################
      - name: "freeholdforecast-sample-etl"
        <<: *basic-static-cluster
        spark_python_task:
          python_file: "file://freeholdforecast/tasks/sample_etl_task.py"
          parameters:
            ["--conf-file", "file:fuse://conf/tasks/sample_etl_config.yml"]
        # tasks:
        #   - task_key: "main"
        #     <<: *basic-static-cluster
        #     python_wheel_task:
        #       package_name: "freeholdforecast"
        #       entry_point: "etl" # take a look at the setup.py entry_points section for details on how to define an entrypoint
        #       parameters: ["--conf-file", "file:fuse://conf/tasks/sample_etl_config.yml"]
      #######################################################################################
      # this is an example job with single ML task based on 2.1 API and wheel_task format #
      ######################################################################################
      - name: "freeholdforecast-sample-ml"
        <<: *basic-static-cluster
        spark_python_task:
          python_file: "file://freeholdforecast/tasks/sample_ml_task.py"
          parameters:
            ["--conf-file", "file:fuse://conf/tasks/sample_ml_config.yml"]
        # tasks:
        #   - task_key: "main"
        #     <<: *basic-static-cluster
        #     python_wheel_task:
        #       package_name: "freeholdforecast"
        #       entry_point: "ml" # take a look at the setup.py entry_points section for details on how to define an entrypoint
        #       parameters: ["--conf-file", "file:fuse://conf/tasks/sample_ml_config.yml"]
      #############################################################
      # this is an example multitask job with notebook task       #
      #############################################################
      - name: "freeholdforecast-sample-multitask"
        job_clusters:
          - job_cluster_key: "default"
            <<: *basic-static-cluster
        tasks:
          - task_key: "etl"
            job_cluster_key: "default"
            spark_python_task:
              python_file: "file://freeholdforecast/tasks/sample_etl_task.py"
              parameters:
                ["--conf-file", "file:fuse://conf/tasks/sample_etl_config.yml"]
          - task_key: "ml"
            depends_on:
              - task_key: "etl"
            job_cluster_key: "default"
            python_wheel_task:
              package_name: "freeholdforecast"
              entry_point: "ml"
              parameters:
                ["--conf-file", "file:fuse://conf/tasks/sample_ml_config.yml"]
          ###############################################################################
          # this is an example task based on the notebook                               #
          # Please note that first you'll need to add a Repo and commit notebook to it. #
          ###############################################################################
          - task_key: "notebook"
            deployment_config:
              no_package: true # we omit using package since code will be shipped directly from the Repo
            depends_on:
              - task_key: "ml"
            job_cluster_key: "default"
            notebook_task:
              notebook_path: "/Repos/Staging/freeholdforecast/notebooks/sample_notebook"
